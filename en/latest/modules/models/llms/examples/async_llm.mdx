 How to use the async API for LLMs
 [#](#how-to-use-the-async-api-for-llms "Permalink to this headline")
=========================================================================================================
 LangChain provides async support for LLMs by leveraging the
 [asyncio](https://docs.python.org/3/library/asyncio.html) 
 library.
 Async support is particularly useful for calling multiple LLMs concurrently, as these calls are network-bound. Currently,
 `OpenAI`
 ,
 `PromptLayerOpenAI`
 ,
 `ChatOpenAI`
 and
 `Anthropic`
 are supported, but async support for other LLMs is on the roadmap.
 You can use the
 `agenerate`
 method to call an OpenAI LLM asynchronously.
```
import time
import asyncio
from langchain.llms import OpenAI
def generate\_serially():
    llm = OpenAI(temperature=0.9)
    for \_ in range(10):
        resp = llm.generate(["Hello, how are you?"])
        print(resp.generations[0][0].text)
async def async\_generate(llm):
    resp = await llm.agenerate(["Hello, how are you?"])
    print(resp.generations[0][0].text)
async def generate\_concurrently():
    llm = OpenAI(temperature=0.9)
    tasks = [async\_generate(llm) for \_ in range(10)]
    await asyncio.gather(\*tasks)
s = time.perf\_counter()
# If running this outside of Jupyter, use asyncio.run(generate\_concurrently())
await generate\_concurrently() 
elapsed = time.perf\_counter() - s
print('\033[1m' + f"Concurrent executed in {elapsed:0.2f} seconds." + '\033[0m')
s = time.perf\_counter()
generate\_serially()
elapsed = time.perf\_counter() - s
print('\033[1m' + f"Serial executed in {elapsed:0.2f} seconds." + '\033[0m')
```
```
I'm doing well, thank you. How about you?
I'm doing well, thank you. How about you?
I'm doing well, how about you?
I'm doing well, thank you. How about you?
I'm doing well, thank you. How about you?
I'm doing well, thank you. How about yourself?
I'm doing well, thank you! How about you?
I'm doing well, thank you. How about you?
I'm doing well, thank you! How about you?
I'm doing well, thank you. How about you?
Concurrent executed in 1.39 seconds.
I'm doing well, thank you. How about you?
I'm doing well, thank you. How about you?
I'm doing well, thank you. How about you?
I'm doing well, thank you. How about you?
I'm doing well, thank you. How about yourself?
I'm doing well, thanks for asking. How about you?
I'm doing well, thanks! How about you?
I'm doing well, thank you. How about you?
I'm doing well, thank you. How about yourself?
I'm doing well, thanks for asking. How about you?
Serial executed in 5.77 seconds.
```