 Hugging Face Length Function
 [#](#hugging-face-length-function "Permalink to this headline")
===============================================================================================
 Most LLMs are constrained by the number of tokens that you can pass in, which is not the same as the number of characters. In order to get a more accurate estimate, we can use Hugging Face tokenizers to count the text length.
1. How the text is split: by character passed in
2. How the chunk size is measured: by Hugging Face tokenizer
```
from transformers import GPT2TokenizerFast
tokenizer = GPT2TokenizerFast.from\_pretrained("gpt2")
```
```
# This is a long document we can split up.
with open('../../../state\_of\_the\_union.txt') as f:
    state\_of\_the\_union = f.read()
from langchain.text\_splitter import CharacterTextSplitter
```
```
text\_splitter = CharacterTextSplitter.from\_huggingface\_tokenizer(tokenizer, chunk\_size=100, chunk\_overlap=0)
texts = text\_splitter.split\_text(state\_of\_the\_union)
```
```
print(texts[0])
```
```
Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  
Last year COVID-19 kept us apart. This year we are finally together again. 
Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. 
With a duty to one another to the American people to the Constitution.
```