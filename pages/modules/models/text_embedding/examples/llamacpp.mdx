 Llama-cpp
 [#](#llama-cpp "Permalink to this headline")
=========================================================
 This notebook goes over how to use Llama-cpp embeddings within LangChain
```
!pip install llama-cpp-python
```
```
from langchain.embeddings import LlamaCppEmbeddings
```
```
llama = LlamaCppEmbeddings(model\_path="/path/to/model/ggml-model-q4\_0.bin")
```
```
text = "This is a test document."
```
```
query\_result = llama.embed\_query(text)
```
```
doc\_result = llama.embed\_documents([text])
```