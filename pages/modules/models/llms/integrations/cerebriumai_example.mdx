 CerebriumAI
 [#](#cerebriumai "Permalink to this headline")
=============================================================
`Cerebrium`
 is an AWS Sagemaker alternative. It also provides API access to
 [several LLM models](https://docs.cerebrium.ai/cerebrium/prebuilt-models/deployment) 
 .
 This notebook goes over how to use Langchain with
 [CerebriumAI](https://docs.cerebrium.ai/introduction) 
 .
 Install cerebrium
 [#](#install-cerebrium "Permalink to this headline")
-------------------------------------------------------------------------
 The
 `cerebrium`
 package is required to use the
 `CerebriumAI`
 API. Install
 `cerebrium`
 using
 `pip3
 install
 cerebrium`
 .
```
# Install the package
!pip3 install cerebrium
```
 Imports
 [#](#imports "Permalink to this headline")
-----------------------------------------------------
```
import os
from langchain.llms import CerebriumAI
from langchain import PromptTemplate, LLMChain
```
 Set the Environment API Key
 [#](#set-the-environment-api-key "Permalink to this headline")
---------------------------------------------------------------------------------------------
 Make sure to get your API key from CerebriumAI. See
 [here](https://dashboard.cerebrium.ai/login) 
 . You are given a 1 hour free of serverless GPU compute to test different models.
```
os.environ["CEREBRIUMAI\_API\_KEY"] = "YOUR\_KEY\_HERE"
```
 Create the CerebriumAI instance
 [#](#create-the-cerebriumai-instance "Permalink to this headline")
-----------------------------------------------------------------------------------------------------
 You can specify different parameters such as the model endpoint url, max length, temperature, etc. You must provide an endpoint url.
```
llm = CerebriumAI(endpoint\_url="YOUR ENDPOINT URL HERE")
```
 Create a Prompt Template
 [#](#create-a-prompt-template "Permalink to this headline")
---------------------------------------------------------------------------------------
 We will create a prompt template for Question and Answer.
```
template = """Question: {question}
Answer: Let's think step by step."""
prompt = PromptTemplate(template=template, input\_variables=["question"])
```
 Initiate the LLMChain
 [#](#initiate-the-llmchain "Permalink to this headline")
---------------------------------------------------------------------------------
```
llm\_chain = LLMChain(prompt=prompt, llm=llm)
```
 Run the LLMChain
 [#](#run-the-llmchain "Permalink to this headline")
-----------------------------------------------------------------------
 Provide a question and run the LLMChain.
```
question = "What NFL team won the Super Bowl in the year Justin Beiber was born?"
llm\_chain.run(question)
```