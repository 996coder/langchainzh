 PromptLayer OpenAI
 [#](#promptlayer-openai "Permalink to this headline")
===========================================================================
`PromptLayer`
 is the first platform that allows you to track, manage, and share your GPT prompt engineering.
 `PromptLayer`
 acts a middleware between your code and
 `OpenAI’s`
 python library.
`PromptLayer`
 records all your
 `OpenAI
 API`
 requests, allowing you to search and explore request history in the
 `PromptLayer`
 dashboard.
 This example showcases how to connect to
 [PromptLayer](https://www.promptlayer.com) 
 to start recording your OpenAI requests.
 Another example is
 [here](https://python.langchain.com/en/latest/ecosystem/promptlayer.html) 
 .
 Install PromptLayer
 [#](#install-promptlayer "Permalink to this headline")
-----------------------------------------------------------------------------
 The
 `promptlayer`
 package is required to use PromptLayer with OpenAI. Install
 `promptlayer`
 using pip.
```
!pip install promptlayer
```
 Imports
 [#](#imports "Permalink to this headline")
-----------------------------------------------------
```
import os
from langchain.llms import PromptLayerOpenAI
import promptlayer
```
 Set the Environment API Key
 [#](#set-the-environment-api-key "Permalink to this headline")
---------------------------------------------------------------------------------------------
 You can create a PromptLayer API Key at
 [www.promptlayer.com](https://www.promptlayer.com) 
 by clicking the settings cog in the navbar.
 Set it as an environment variable called
 `PROMPTLAYER\_API\_KEY`
 .
 You also need an OpenAI Key, called
 `OPENAI\_API\_KEY`
 .
```
from getpass import getpass
PROMPTLAYER\_API\_KEY = getpass()
```
```
os.environ["PROMPTLAYER\_API\_KEY"] = PROMPTLAYER\_API\_KEY
```
```
from getpass import getpass
OPENAI\_API\_KEY = getpass()
```
```
os.environ["OPENAI\_API\_KEY"] = OPENAI\_API\_KEY
```
 Use the PromptLayerOpenAI LLM like normal
 [#](#use-the-promptlayeropenai-llm-like-normal "Permalink to this headline")
-------------------------------------------------------------------------------------------------------------------------
*You can optionally pass in
 `pl\_tags`
 to track your requests with PromptLayer’s tagging feature.* 
```
llm = PromptLayerOpenAI(pl\_tags=["langchain"])
llm("I am a cat and I want")
```
**The above request should now appear on your
 [PromptLayer dashboard](https://www.promptlayer.com) 
 .** 
 Using PromptLayer Track
 [#](#using-promptlayer-track "Permalink to this headline")
-------------------------------------------------------------------------------------
 If you would like to use any of the
 [PromptLayer tracking features](https://magniv.notion.site/Track-4deee1b1f7a34c1680d085f82567dab9) 
 , you need to pass the argument
 `return\_pl\_id`
 when instantializing the PromptLayer LLM to get the request id.
```
llm = PromptLayerOpenAI(return\_pl\_id=True)
llm\_results = llm.generate(["Tell me a joke"])
for res in llm\_results.generations:
    pl\_request\_id = res[0].generation\_info["pl\_request\_id"]
    promptlayer.track.score(request\_id=pl\_request\_id, score=100)
```
 Using this allows you to track the performance of your model in the PromptLayer dashboard. If you are using a prompt template, you can attach a template to a request as well.
Overall, this gives you the opportunity to track the performance of different templates and models in the PromptLayer dashboard.