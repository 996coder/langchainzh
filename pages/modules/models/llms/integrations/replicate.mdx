 Replicate
 [#](#replicate "Permalink to this headline")
=========================================================
> 
> 
> 
> [Replicate](https://replicate.com/blog/machine-learning-needs-better-tools) 
>  runs machine learning models in the cloud. We have a library of open-source models that you can run with a few lines of code. If you’re building your own machine learning models, Replicate makes it easy to deploy them at scale.
>  
> 
> 
> 
> 
 This example goes over how to use LangChain to interact with
 `Replicate`
[models](https://replicate.com/explore) 
 Setup
 [#](#setup "Permalink to this headline")
-------------------------------------------------
 To run this notebook, you’ll need to create a
 [replicate](https://replicate.com) 
 account and install the
 [replicate python client](https://github.com/replicate/replicate-python) 
 .
```
!pip install replicate
```
```
# get a token: https://replicate.com/account
from getpass import getpass
REPLICATE\_API\_TOKEN = getpass()
```
```
 ········
```
```
import os
os.environ["REPLICATE\_API\_TOKEN"] = REPLICATE\_API\_TOKEN
```
```
from langchain.llms import Replicate
from langchain import PromptTemplate, LLMChain
```
 Calling a model
 [#](#calling-a-model "Permalink to this headline")
---------------------------------------------------------------------
 Find a model on the
 [replicate explore page](https://replicate.com/explore) 
 , and then paste in the model name and version in this format: model\_name/version
 For example, for this
 [dolly model](https://replicate.com/replicate/dolly-v2-12b) 
 , click on the API tab. The model name/version would be:
 `replicate/dolly-v2-12b:ef0e1aefc61f8e096ebe4db6b2bacc297daf2ef6899f0f7e001ec445893500e5`
 Only the
 `model`
 param is required, but we can add other model params when initializing.
 For example, if we were running stable diffusion and wanted to change the image dimensions:
```
Replicate(model="stability-ai/stable-diffusion:db21e45d3f7023abc2a46ee38a23973f6dce16bb082a930b0c49861f96d1e5bf", input={'image\_dimensions': '512x512'})
```
*Note that only the first output of a model will be returned.* 
```
llm = Replicate(model="replicate/dolly-v2-12b:ef0e1aefc61f8e096ebe4db6b2bacc297daf2ef6899f0f7e001ec445893500e5")
```
```
prompt = """
Answer the following yes/no question by reasoning step by step. 
Can a dog drive a car?
"""
llm(prompt)
```
```
'The legal driving age of dogs is 2. Cars are designed for humans to drive. Therefore, the final answer is yes.'
```
 We can call any replicate model using this syntax. For example, we can call stable diffusion.
```
text2image = Replicate(model="stability-ai/stable-diffusion:db21e45d3f7023abc2a46ee38a23973f6dce16bb082a930b0c49861f96d1e5bf", 
                       input={'image\_dimensions': '512x512'})
```
```
image\_output = text2image("A cat riding a motorcycle by Picasso")
image\_output
```
```
'https://replicate.delivery/pbxt/Cf07B1zqzFQLOSBQcKG7m9beE74wf7kuip5W9VxHJFembefKE/out-0.png'
```
 The model spits out a URL. Let’s render it.
```
from PIL import Image
import requests
from io import BytesIO
response = requests.get(image\_output)
img = Image.open(BytesIO(response.content))
img
```
![../../../../_images/506447a6eb1b49eb4e95c212b6e58965789809b619f0b328903e14e508982165.png](../../../../_images/506447a6eb1b49eb4e95c212b6e58965789809b619f0b328903e14e508982165.png)
 Chaining Calls
 [#](#chaining-calls "Permalink to this headline")
-------------------------------------------------------------------
 The whole point of langchain is to… chain! Here’s an example of how do that.
```
from langchain.chains import SimpleSequentialChain
```
 First, let’s define the LLM for this model as a flan-5, and text2image as a stable diffusion model.
```
dolly\_llm = Replicate(model="replicate/dolly-v2-12b:ef0e1aefc61f8e096ebe4db6b2bacc297daf2ef6899f0f7e001ec445893500e5")
text2image = Replicate(model="stability-ai/stable-diffusion:db21e45d3f7023abc2a46ee38a23973f6dce16bb082a930b0c49861f96d1e5bf")
```
 First prompt in the chain
```
prompt = PromptTemplate(
    input\_variables=["product"],
    template="What is a good name for a company that makes {product}?",
)
chain = LLMChain(llm=dolly\_llm, prompt=prompt)
```
 Second prompt to get the logo for company description
```
second\_prompt = PromptTemplate(
    input\_variables=["company\_name"],
    template="Write a description of a logo for this company: {company\_name}",
)
chain\_two = LLMChain(llm=dolly\_llm, prompt=second\_prompt)
```
 Third prompt, let’s create the image based on the description output from prompt 2
```
third\_prompt = PromptTemplate(
    input\_variables=["company\_logo\_description"],
    template="{company\_logo\_description}",
)
chain\_three = LLMChain(llm=text2image, prompt=third\_prompt)
```
 Now let’s run it!
```
# Run the chain specifying only the input variable for the first chain.
overall\_chain = SimpleSequentialChain(chains=[chain, chain\_two, chain\_three], verbose=True)
catchphrase = overall\_chain.run("colorful socks")
print(catchphrase)
```
```
> Entering new SimpleSequentialChain chain...
novelty socks
todd & co.
https://replicate.delivery/pbxt/BedAP1PPBwXFfkmeD7xDygXO4BcvApp1uvWOwUdHM4tcQfvCB/out-0.png
> Finished chain.
https://replicate.delivery/pbxt/BedAP1PPBwXFfkmeD7xDygXO4BcvApp1uvWOwUdHM4tcQfvCB/out-0.png
```
```
response = requests.get("https://replicate.delivery/pbxt/eq6foRJngThCAEBqse3nL3Km2MBfLnWQNd0Hy2SQRo2LuprCB/out-0.png")
img = Image.open(BytesIO(response.content))
img
```
![../../../../_images/5dc162007c5fcb88c9c7258d9d640be72c221c32ec99698a94781095ba4a3217.png](../../../../_images/5dc162007c5fcb88c9c7258d9d640be72c221c32ec99698a94781095ba4a3217.png)